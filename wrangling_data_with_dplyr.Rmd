---
title: "R4DS - Wrangling Data with dplyr"
author: "Fisher Ankney"
date: "February 18, 2018"
output: html_document
---
This is the third of a six-part series summarizing the core concepts of Hadley Wickham's textbook, R for Data Science <http://r4ds.had.co.nz/>. In the previous [post](link) I've abridged the book’s chapters that cover data handling with readr.

In this post, I’ll be focusing on the dplyr package. I consider dplyr to be the centr peice and of the tidyverse, unfortunately it also has the steepest learning curve. I'm not going to attempt to teach dplyr to you, the only way to learn it is through hours of practice, instead I hope to offer a quick refresher on functions, what they do, and examples of their use. 


For more useful resources on dplyr, reference these links:

- 
- 
- 

<br  />

#### Libraries
```{r, message=FALSE}
library('nycflights13')   # example dataset 
library('tidyverse')      # includes dplyr
library('dplyr')          # dplyr specifically
```

<br  />
 
 Many assert that over 80% of an analytical project is data wrangling, that makes for ample opportunity to become a masterful dplyr user. Seven core functions make up the core component of dplyr. They can be easy to mix up at first, so I've created this list with a short comment to help you keep them straight. Below this list of seven primary dplyr commands is a longer list of secondary commands. Although used less commonly, these cmmands can also be helpful in a variety of circumstances. 
 
<br  />

#### Primary Commands
```{r, eval=FALSE}
filter()       # select rows based on value 
arrange()      # sort rows based on values 
select()       # zoom in on specified columns
mutate()       # create new variables from existing ones 
summarise()    # collapse dataframe to single summary
group_by()     # analyze by specified group, useful for summarise 
%>%            # connecting pipe, read as "then"
```

<br  />

#### Secondary Commands 
```{r, eval=FALSE}
transmute()    # create new variables from existing ones, destroy existing ones
ungroup()      # literally the name
rename()       # literally the name 
desc()         # descending order (large to small, z to a)
count()        # simple function counting entries in a variable
n()            # number of entries
lag()          # offset, allows to refer to lagging (-1) value
lead()         # offset, allows to refer to leading (+1) value
cumsum()       # cumulative sum, also prod, mean, min, max 
```

<br  />

There's a lot to go through, I'll just explore primary commands in straight foward examples. Again the best way to learn dplyr is to use it. Hadley Wickham's R for Data Science book offers hours worth of challenges using the flights dataset, these are just the most straight forward usages.

<br  />

#### Dataset 
```{r}
flights
```

<br  />

The flights dataset gives on-time data for all flights that departed from New York City in 2013. There are 19 columns or variables, and 336,776 rows or observations. A large and diverse dataset such as flights is perfect for learning how to use dplyr. 

<br  /> 

#### Filter
```{r}
filter(flights, month == 12 & day == 25)
```

<br  />

Filter finds rows in which a condition is true. In the above example the filter function is used on the flights dataset, as declared in the first arguement. A set of condition follows - the months variable must equal 12 (December), and the day variable must also equal 25. These conditions return a flights dataset with only 719 observations, these are the 719 flights that departed New York City on Christmas Day, 2013. 

<br  />

#### Arrange
```{r}
arrange(flights, desc(dep_time))
```

<br  />

Arrange is a simple function, it reorders observations in a described fashion. The above example reorders the flights dataset by descending departure time. In other words, flights with the greatest (latest) departure time are moved to the top of the dataset. Flights with the least (earliest) departure time are moved to the bottom of the dataset. 

<br  /> 

#### Select
```{r}
select(flights, year:day)
```

<br  />

Select keeps only the variables you mention as arguements behind the initial dataframe arguement. In the above example, select returns all observations between the year and day variable, in this case that just means the month variable. 

<br  />

#### Mutate
```{r}
mutate(flights, speed = distance / air_time * 60)
```

<br  />

Mutate adds a new variable based on the existing variables, while retaining these existing variables. In the above example, mutate creates a variable flight, which takes each observations distance value, divides it by each observations air_time value, then multiplies the product? by 60. Mutatedoes vectorized math. 

<br  />

#### Summarise
```{r}
summarise(flights, delay = mean(dep_delay)) 
```

<br  />

Summarise doesnt seem to be working right now. The output has one row for each group. In the above example summarise creates a new variable, yeah I dont really know how to use summarise correctly. look this up. 

<br  />

#### Group By
```{r}
group_by(flights, dest) %>%                        # group flights by destination
  summarise(count = n(),                           # summarise # of flights have invidual dest as variable "count"
            dist = mean(distance, na.rm = TRUE),   # distance = mean distance to each group_by() destination
            delay = mean(arr_delay, na.rm = TRUE)  # delay = mean arrival delay for each group_by() destination
            ) 
```

<br  /> 

A function that compliments summarise nicely, group by does groups by. in the above example... 

<br  />

#### Complex Inqueries
```{r}
denver_xmas_delay <- flights %>%                          # create new dataframe, denver_xmas_delay
  select(-tailnum) %>%                                    # leave out tailnum from new dataframe
  filter(month == 12 & day == 25 & dest == "DEN") %>%     # only keep christmas day flights, destination denver
  group_by(carrier) %>%                                   # group further analysis by carrier company
  summarise(num_flights = n(),                            # num_flights that fits analysis, grouped by carrier
            avg_delay = mean(dep_delay)) %>%              # average delay (by carrier) = mean(departure delay)
  arrange(desc(avg_delay))                                # arrange (by carrier) by biggest delay
denver_xmas_delay                                         # print results
```

All of these primary functions can be strung together using the %>% 'then' pipe, and any combination of the forementioned secondary commands. Build up the chain one command at a time, don't try to write it all then run it all at once. Possible to sort through millions of elements with relative ease, create new elements, focus your data analysis, extract meaning from enormous and complex datasets. dplyr is truely the bread and butter of data science with R, it may frusterate at times but it's an extremely powerful tool. 

Read the chapter on it if you'd like practice, again this is just a quick reference if you forget the important core components of dplyr or how to use them. 

If you found this summary helpful, stay tuned for part four of the R4DS summary series, Tidy Data with tidyr. 

Until next time, <br  />
\- Fisher
