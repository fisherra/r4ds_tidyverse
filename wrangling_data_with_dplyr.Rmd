---
title: "R4DS - Wrangling Data with dplyr"
author: "Fisher Ankney"
date: "February 18, 2018"
output: html_document
---
This is the third installment of a six-part series summarizing the   concepts of Hadley Wickham's textbook, [R for Data Science](http://r4ds.had.co.nz/). In the previous blog [post](link) I've abridged the book’s chapters that cover importing, parsing, and exporting data with readr.

In this post, I’ll be focusing on chapter five which covers data transformation primarly with the dplyr package. I consider dplyr to share tidyverse center stage with ggplot2; unfortunetly dplyr has a steeper learning curve than it's co-star. I've written a post on data visualization with ggplot2 [here](post). In the case of dplyr, it is best learned through hours of practice rather than careful explaination. As such, I hope to offer an easily understood reference guide in this post, rather than a detailed tutorial.

For more in-depth resources on dplyr, reference these links:

- 
- 
- 

<br  />

#### Libraries
```{r, message=FALSE}
library('nycflights13')   # example dataset 
library('tidyverse')      # includes dplyr
library('dplyr')          # dplyr specifically
```

<br  />
 
Some data scientists assert that over 80% of their time is used wrangling data; see this as an opportunity and important reason to master the art of dplyr. If you're looking to make the most of your data analysis routine, it makes sense to streamline the largest portion of your work-load before seeking efficiency elsewhere. 

I've compiled this list of seven primary commands that form the core of dplyr's functionality. These are the most influential and called upon functions in the dplyr package. Seven second-tier functions follow; these commands are commonly useful but not as influential as the primary functions listed before them. 

<br  />

#### Primary Functions
```{r, eval=FALSE}
filter()       # select rows based on value 
arrange()      # sort rows based on values 
select()       # zoom in on specified columns
mutate()       # create new variables from existing ones 
summarise()    # collapse dataframe to single summary
group_by()     # analyze by specified group, useful for summarise 
%>%            # connecting pipe, read as "then"
```

<br  />

#### Secondary Functions
```{r, eval=FALSE}
transmute()    # create new variables from existing ones, remove existing variables
ungroup()      # literally the name
desc()         # descending order (large to small, z to a)
count()        # simple function counting entries in a variable
n()            # number of entries
lag()          # offset, allows to refer to lagging (-1) value
lead()         # offset, allows to refer to leading (+1) value
```

<br  />

Of these functions I'll specifically examplify the first seven, and attempt to include the second seven throughout. Again, the goal of this post is to be a quick-reference as to the functionality of dplyr, not an in dpeth tutorial. The best way to learn data wrangling is experience, [R for Data Science Chapter 5](http://r4ds.had.co.nz/transform.html) has many examples and challenges you can work through to solidify your dplyr skills. 

<br  />

#### Example Dataset 
```{r}
flights
```

<br  />

Flights is a classic dataset that is large and diverse, perfect for testing out the primary functions of dpylr. This dataset gives on-time data for all flights that departed from New York City in 2013. There are 19 columns or variables, and 336,776 rows or observations. 

<br  /> 

#### Filter
```{r}
filter(flights, month == 12 & day == 25)
```

<br  />

*Filter* is a simple function that finds, or 'filters' observations that match true to a declared condition. In this example *filter* first's arguement is the flights dataset, the following arguements declare the conditions to be met. Retain observations (rows) with the months variable equal to 12, and the day variable equal to 25. The result is a dataframe with 719 flights that departed New York City on Christmas Day, 2013. 

<br  />

#### Arrange
```{r}
arrange(flights, desc(dep_time))
```

<br  />

Often times observations within a dataframe are ordered arbitrarily, or unproductively. *Arrange* reorders observations according to it's user specified arguements. In this exmaple the flights dataframe is called upon as the first arguement once again; this is common syntax within dplyr functions and I won't be referencing it henceforth. The second argeument is *desc(dep_time)*. *desc* is one of the secondary functions listed previously; it simply transforms a vector into a format that will be sorted in descending order. *dep_time* is the flights variable departure time, a number from 0000 to 2400, indicating the actual departure time of an individual aircraft. The resulting dataframe has all 336,776 observations sorted from latest (highest) to earliest (lowest) departure time. 

<br  /> 

#### Select
```{r}
select(flights, year:day)
```

<br  />

Select keeps only the variables you mention as arguements behind the initial dataframe arguement. In the above example, select returns all observations between the year and day variable, in this case that just means the month variable. 

<br  />

#### Mutate
```{r}
mutate(flights, speed = distance / air_time * 60)
```

<br  />

Mutate adds a new variable based on the existing variables, while retaining these existing variables. In the above example, mutate creates a variable flight, which takes each observations distance value, divides it by each observations air_time value, then multiplies the product? by 60. Mutatedoes vectorized math. 

<br  />

#### Summarise
```{r}
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
```

<br  />

Summarise doesnt seem to be working right now. The output has one row for each group. In the above example summarise creates a new variable, yeah I dont really know how to use summarise correctly. look this up. 

<br  />

#### Group By
```{r}
group_by(flights, dest) %>%                        # group flights by destination
  summarise(count = n(),                           # summarise # of flights have invidual dest as variable "count"
            dist = mean(distance, na.rm = TRUE),   # distance = mean distance to each group_by() destination
            delay = mean(arr_delay, na.rm = TRUE)  # delay = mean arrival delay for each group_by() destination
            ) 
```

<br  /> 

A function that compliments summarise nicely, group by does groups by. in the above example... 

<br  />

#### Complex Inqueries
```{r}
denver_xmas_delay <- flights %>%                          # create new dataframe, denver_xmas_delay
  select(-tailnum) %>%                                    # leave out tailnum from new dataframe
  filter(month == 12 & day == 25 & dest == "DEN") %>%     # only keep christmas day flights, destination denver
  group_by(carrier) %>%                                   # group further analysis by carrier company
  summarise(num_flights = n(),                            # num_flights that fits analysis, grouped by carrier
            avg_delay = mean(dep_delay)) %>%              # average delay (by carrier) = mean(departure delay)
  arrange(desc(avg_delay))                                # arrange (by carrier) by biggest delay
denver_xmas_delay                                         # print results
```

All of these primary functions can be strung together using the %>% 'then' pipe, and any combination of the forementioned secondary commands. Build up the chain one command at a time, don't try to write it all then run it all at once. Possible to sort through millions of elements with relative ease, create new elements, focus your data analysis, extract meaning from enormous and complex datasets. dplyr is truely the bread and butter of data science with R, it may frusterate at times but it's an extremely powerful tool. 

Read the chapter on it if you'd like practice, again this is just a quick reference if you forget the important core components of dplyr or how to use them. 

If you found this summary helpful, stay tuned for part four of the R4DS summary series, Tidy Data with tidyr. 

Until next time, <br  />
\- Fisher
