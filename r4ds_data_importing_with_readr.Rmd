---
title: "R4DS - File Management and readr"
author: "Fisher Ankney"
date: "February 10, 2018"
output: html_document
---
This is the second of a six part series summarsing the core concepts of Hadley Wickham's R for Data Science: <http://r4ds.had.co.nz/>. In the previous post, I've written about the R4DS chapters covering data visualization using ggplot2, you can find that post [here](site.baseurl/).

Today I'll summarize importing and exporting data with the readr library as covered in R4DS. I'll also add my own two cents on how to keep an R project tidy and easily replicable. While these topics may sound trivial, they can become a huge headache later on if you don't tend to them. An unorganized project can causing important scripts to go missing, original data to be overwritten, and reproducability to be thrown out the window. 

For more useful resources, check out these links:    

#### Load Libraries
```{r, message=FALSE}
library('tidyverse') # used for many amazing things, includes readr library
library('readr')     # used to read in a variety of file types
library('readxl')    # used for reading in microsoft excel files
```

You may also be interested in the following libraries, however I won't cover them in this blog post - 

```{r, eval=FALSE}
library('haven')   # used for SPSS, SAS, and Strata input files
library('DBl')     # used for database files, must combine with specific backend
library('RMySQL')  # used for MySQL backend (with DBl)
```

<br  />

## Organizing a Project in R

Properly organizing a project can be really simple, but it's something that a lot of people don't bother to talk about. Whenever I'm starting a new project, I create a new folder in my documents, giving the project an obvious title, such as turtle_analysis. I always use [snake_case](https://en.wikipedia.org/wiki/Snake_case) while working with projects in R. Once I've created te project folder I'll change my working directory to the project folder and then initiate a git repository. 

Creating git repositories and effectively using Github is an entire series of blog posts by itself. For the purposes of this post I'll just point you to Data Camp's [Introduction to Git for Data Science](https://www.datacamp.com/courses/introduction-to-git-for-data-science). It's a free and high quality four hour course that teaches you everything you need to know about git technology. While you're there, check out [Introduction to Shell for Data Science](https://www.datacamp.com/courses/introduction-to-shell-for-data-science) as well. 

Once you've followed intiated a git repository inside your project folder you're ready to structure the folder. My project folders always end up looking something like this:

#### turtle_analysis/
|- input/ <br  />
|\-\-\- about_turtles.txt <br  />
|\-\-\- ocean_temp.csv <br  />
|\-\-\- turtle_sizes.csv <br  />
| <br  />
|- scripts/ <br  />
|\-\-\- turtle_eda.R <br  />
|\-\-\- turtle_height_plot.R <br  />
|\-\-\- turtle_width_plot.R <br  />
| <br  />
|- output/ <br  />
|\-\-\- turtle_height.png <br  />
|\-\-\- turtle_width.png <br  />
| <br  />
|- final_analysis.Rmd <br  />
|- final_analysis.html <br  />
|- README.md <br  /> 

explain input output script

explain how each script should load libraries in data in the script, linking the data to the script to the output for easy reproducability

explain final_analysis.Rmd and generated .html

explain readme.md (for github if you're into that)

## Reading and Writing Files with readr

#### setting directories 
setwd()
getwd()

#### reading functions 
local paths
local data types
online paths

#### parsing data
- columns
- date-times
- all that nonsense

#### writing data 
- goes to outputs
-scripts save in scripts
