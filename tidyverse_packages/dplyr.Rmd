---
title: "Unpacking the Tidyverse - dplyr"
author: "Fisher Ankney"
date: "February 18, 2018"
output: html_document
---

<br> 

### Introduction 

This is the third of eight installments of my *Unpacking the Tidyverse* series. Each installment focuses on one of the eight core packages in Hadley Wickham's tidyverse. Instructions given in each post are mainly derived from Hadley's textbook, [R for Data Science](http://r4ds.had.co.nz/), and CRAN package documentation. This installment of *Unpacking the Tidyverse* focuses on the data-wrangling package, dplyr. The previous installment focuses on the readr package, and can be found [here](link). The next installment focuses on the tidyr package, and can be found [here](link). 

When it comes to data wrangling, the best teacher is experience. Only through hours of using dplyr will you become proficient with it. Many professional data scientists report that more than 80% of their time is spent data wrangling, so there is endless opportunity to practice with dplyr! 

dplyr is by far the largest tidyverse package, it contains countless functions to help with all of your data wrangling needs. In this post, I'll focus on the three families of dplyr functions that I find the most useful: the five data-wrangling verbs, six types of data joins, and an assortment of helper functions. 

<br> 

```{r, message=FALSE}
library('tidyverse')      # includes dplyr
library('nycflights13')   # example dataset 
```

<br>

### Dplyr Overview

<br> 

#### Data Manipulation Verbs 

```{r, eval=FALSE}
filter()       # select rows based on value 
arrange()      # sort rows based on values 
select()       # zoom in on specified columns
mutate()       # create new variables from existing ones 
summarize()    # collapse dataframe to single summary
group_by()     # analyze by specified group, useful for summarize 
%>%            # connecting pipe, read as "then"
```

<br  />

#### Two-Table Functions

```{r, eval=F}
inner_join()   # 
full_join()    # 
left_join()    #
right_join()   #
semi_join()    #
anti_join()    #
```

<br> 

#### Data Wrangling Functions
```{r, eval=FALSE}
transmute()    # create new variables from existing ones, remove existing variables
ungroup()      # literally the name
desc()         # descending order (large to small, z to a)
count()        # simple function counting entries in a variable
n()            # number of entries
lag()          # offset, allows to refer to lagging (-1) value
lead()         # offset, allows to refer to leading (+1) value
starts_with()  # 
ends_with()    #
contains()     #
matches()      #
num_range()    #
bind_rows()    #
bind_cols()    # 
rename()       # 
select()       # 
tally()        # 
first()        # the first element of vector x
last()         # the last element
nth()          # the nth element 
n()            # the number of rows in the dataframe that summarise() describes
n_distinct()   # number of unique values in vector x 
```

<br  />

I've broken down this post on dplyr into three distinct sections - Data Manipulation Verbs, Two-Table Functions, and Data Wrangling Functions. The first section, data maniulation verbs, covers what I believe are the six most important functions in dplyr along with "then" pipe. If you only read one section of this post, I suggest you make it this section. Also of importance are the two-table functions introduced in dplyr. These six "join" functions allow the user complete control when combining multiple datasets. Finally, the data wrangling functions are functions that I've found useful in niche cases while exploring and analyzing datasets. This isn't a complete list of data wrangling functions in dplyr, they're just functions that I've personally found useful in my projects thus far. 

To demonstrate the power of dplyr, we'll be working with the flights dataset loaded from `library(nycflights13)`. Flights is a large and diverse dataset, containing 19 variables and over 335,000 observations. Flights gives on-time data for all flights that departed from the three airports associated with New York City in 2013. 

<br> 

```{r}
flights
```

<br  />

#### Filter

`filter()` is a simple function that finds, or 'filters' observations that match true to a declared condition. In this example `filter()` first's argument is the flights dataset, the following arguments declare the conditions to be met. Retain observations (rows) with the months variable equal to 12, and the day variable equal to 25. The result is a dataframe with 719 flights that departed New York City on Christmas Day, 2013. 

```{r}
filter(flights, month == 12 & day == 25)
```

<br  />

#### Arrange

Often observations within a dataframe are ordered arbitrarily, or unproductively. `arrange()` reorders observations according to its user specified arguments. In this example, the flights dataframe is called upon as the first argument once again; this is common syntax within dplyr functions and I won't be referencing it henceforth. The second argument is `desc(dep_time)`. `desc()` is one of the secondary functions listed previously; it simply transforms a vector into a format that will be sorted in descending order. `dep_time` is the flights variable departure time, a number from 0000 to 2400, indicating the actual departure time of an individual aircraft. The resulting dataframe has all 336,776 observations sorted from latest (highest) to earliest (lowest) departure time. 


```{r}
arrange(flights, desc(dep_time))
```

<br  /> 

#### Select

In a dataframe with numerous variables it's easy become overwhelmed and broad with analysis. `select()` reduces the number of variables in a dataframe, only keeping variables that the user inputs as arguments. In this example, flights are reduced from 19 variables to the variables year, month and day. 

```{r}
select(flights, year:day)
```


<br  />

#### Mutate

`mutate()` allows users to alter current variables and create new ones through various vectorized functions. In the above example the variable speed is created and is equal to distance divided by air time multiplied by 60. The pipe function %>%, is used to move the `mutate()` output to `select()`. The new variable, speed, is output by the `select()` function, along with each flight's tail number, air time, and travel distance.


```{r}
mutate(flights, speed = distance / air_time * 60) %>%
  select(tailnum, distance, air_time, speed)
```

<br  />



#### Summarize


`summarize()` is perhaps the most complicated function in dplyr. Often used in conjunction with `group_by()`, `summarize()` collapses many values into a single summary. In the above example. `summarize()` finds the mean departure delay of all 336,776 observations in the flights dataset. As a result, the single value 12.64 (minutes) summarizes the mean departure delay. 

```{r}
summarize(flights, delay = mean(dep_delay, na.rm = TRUE))
```

<br  />

#### Group By

`summarize()` becomes extremely useful when paired with the final primary dplyr function, `group_by()`. `group_by()` changes the unit of analysis from the complete dataset to an individual group, thus changing the scope of summarize. In the above example, the flights dataset is grouped by the dest variable, destination. Grouping by destination by itself does nothing to the dataframe, so the then pipe, %>%, is used to push the output to the `summarize()` function. Summarize first creates a count variable that is equivalent to the function `n()`. `n()` is another one of those secondary dplyr functions that often comes in handy; `n()` is a function that finds the number of observations in the current group. Next, `summarize()` creates a variable named distance based off the mean distance travelled by each observation, as grouped by destination. Finally, `summarize()` creates a variable named delay, based off the mean arrival delay each observation experienced, as grouped by destination. The resulting dataframe gives excellent insight into each of the 105 destinations present in the flights dataset. 


```{r}
group_by(flights, dest) %>%                       
  summarize(count = n(),                          
            dist = mean(distance, na.rm = TRUE),  
            delay = mean(arr_delay, na.rm = TRUE) 
            ) 
```

<br  /> 

#### Complex Inquiries

```{r}
denver_xmas_delay <- flights %>%                          # create new dataframe, denver_xmas_delay, then
  select(-tailnum) %>%                                    # select all variables except for tailnum 
  filter(month == 12 & day == 25 & dest == "DEN") %>%     # filter only flights with destination Denver on Christmas
  group_by(carrier) %>%                                   # now group fights by carrier company for summary analysis
  summarize(num_flights = n(),                            # create num_flights variable, equal to the count sorted by carrier
            avg_delay = mean(dep_delay)) %>%              # create avg_delay variable, equal to mean departure delay by carrier
  arrange(desc(avg_delay))                                # arrange these carriers by the new avg_delay variable
denver_xmas_delay                                         # print results
```

<br>
<br> 

### Two-Table Functions 

There are two types of two-table joining functions, mutating joins and filtering joins. Mutating joins allow you to add new variables from one table to matching observations in another table. these functions are `left_join()`, `right_join()`, `inner_join()`, and `outter_join()`. Filtering Joins filter observations from one table based on matched observations in the secondary table; these two functions are `semi_join()` and `anti_join()`. 

All six of the join functions are structure for the first arguements to be `x` and `y`. These are the tables that are combined or filtered; the output always takes the same structure as the left table, `x`. The third arguement, `by` defines the "key", a column that occurs in both tables that you want to join. They key in the first table is declared the "primary key", the key in the second table is declared the secondary, or foreign key. The Primary key must uniquely ID each row in the first dataset, but not necissarly the second dataset. This means in some cases that the primary key is more than one column. 

They trick to understanding the six join functions is understanding how to use the key values. Let's get started with the most popular function, `left_join()`. 

<br> 

#### Left Join 

The `left_join()` function keeps all observations in your left table (arguement `x`). Your primary table will never lose observations when using left join, it will only gain additional observations from the right table (arguement `y`) based on the defined key. 

Here we'll set up a simple example tibbles - 
```{r}
tib_1 <- tibble(x = 1:2, y = 2:1)
tib_1

tib_2 <- tibble(x = c(1,3), a = 10, b = "a")
tib_2
```

<br>

```{r}
left_join(tib_1, tib_2, by = "x")
```

<br> 

When you don't list a `by` arguement, dplyr finds the key columns on it's own, most of the time it's right, but not always. 

```{r}
left_join(tib_1, tib_2)
```

<br> 

#### Right Join

The mirror image of `left_join()`, `right_join()` includes all of the columns in the `y` table, and adds matching observations from the `x` table. 

```{r}
right_join(tib_1, tib_2)
```


<br> 

#### Inner Join

`inner_join()` is simple, it only includes observations that are present in both `x` and `y`. Every row must be present in both datasets. With the key `by = "x"`, only one row is present in both of these example tibbles. 

```{r}
inner_join(tib_1, tib_2, by = "x")
```

<br> 

#### Full Join

The most inclusive join of all, `full_join()` joins every observation from both tables, as the name suggests. 

```{r}
full_join(tib_1, tib_2, by = "x")
```

<br> 

#### Semi Join

The first of two filter joins, `semi_join()`, keeps all observations in the `x` arguement that have a match in the `y` arguement. In this example, the key is the "x" column of `tib_1`; the only row that matches in `tib_2` is the observation x = 1. Thus, the resulting semi_join only has one observation filtered from `tib_1`. 

```{r}
semi_join(tib_1, tib_2, by = "x")
```

<br> 

#### Anti Join

`anti_join()` is the antithesis of `semi_join()`, the function only returns observations that are not present in the `y` dataset. 

```{r}
anti_join(tib_1, tib_2)
```

<br> 

### Data Wrangling Functions 

<br>

#### `transmute()`  
Technically a data manipulation verb, transmute adds a new variable to the data structure, just like mutate. The difference between transmute and mutate is that mutate preserves the pre-existing variabes while transmute drops them. Usage arguements are exactly the same as mutate. 

#### `ungroup()` 
After using the function `group_by()` data operations are performed on the groups defined by this functions output. Ungroup will undo the effects of `group_by()`, allowing for verbs like `summarize()` to once again be conducted on the entire dataset. 


#### `desc()`
When using the data wrangling verb `arrange()`, dplyr automatically sorts a datasets observations alphanumerically. If, for instance, you wanted to arrange a set of values from highest to lowest, you must use the `desc()` function inside arrange. I eximplify `desc()` in the `arrange()` example code above. 

#### `tally()`   
`tally()` is short hand for the function `summarize()`. The function simply calls the `n()` function, which defines the number of entries in your `x` arguement. If you're calling `tally()` multiple times for a single dataset, it will call `sum(n)`, and create a cumulative tally. `tally()` will takes an `x` arguement and optionally a `wt` and `sort` arguement. `x` is the table to count, `wt` allows for a weighted tally through the defined variable `wt`, and `sort` will sort the output in descending order of n if left as TRUE. 

#### `count()`
A very similiar function to `tally()`, `count()` calls `group_by()` before performing the tally, then calls `ungroup()` once it's complete. 

#### `n_distinct()` 
number of unique values in vector x 

#### `starts_with()` 
Useful with the `select()` data wrangling verb, `starts_with()` allows you to select data entries that start with a defined prefix. The first arguement is a string that you want to match within the dataset; the second arguement is `ignore.case` which defaults to TRUE. 

#### `ends_with()`    
Similiar to `starts_with()`, this verb allows you to select entries from a dataset that end with a defined string. 

#### `contains()`     
Allows you to `select()` data entries that contain a defined literal string anywhere within them. 

#### `matches()`     
Allows you to `select()` data entries that match a regular expression anywhere within them. 

#### `num_range()`   
Allows you to `select()` data entries that contain a defined range of numbers given as the first arguement in `num_range()`. 

#### `bind_rows()`    

#### `bind_cols()`     


#### `rename()`        


#### `first()`
the first element of vector x

#### `last()`
the last element



<br> 
<br> 
<br> 

union() provides an easy way to combine two datasets without duplicating any values 
intersect() set operator equivalent for semi-join, what you would use if your datasets have the exact same variables. 

setdiff() does the same thing as anti_join() but uses every column as a key 

setequal() to check if two datasets contain the same rows in any order, returns T/F

bind_rows() - I really dont understand the .id arguement, useful for turning lists into one large table or dataframe
bind_cols() 

data_frame() 
as_data_frame() - turns lists into dataframe

dplyr doesnt coerce data, except for factors, but gives warning

rownames_to_column(name of dataframe, name of new column to add) - might be useful

also colorRampPalette() can be a pretty fun RColorBrewer Tool  :) 

rename(data, new_name = old_data) - very useful 

you can use select() to rename columns with an equals 

reduce function from purrr

tables <- list(surnames, first, middle) 

reduce(tables, left_join, by = "name")

tally() counts things




### Additional Resources 

- a 
- b 
- c 

Dplyr can often be a frustrating package to work with, but once you've become proficient at data wrangling, Hadley Wickham's package becomes near indispensable. Hopefully this reference guide can help you on your journey to mastering dplyr and data wrangling with R. Stay tuned for part four of the six part R4DS summary series, tidy data with tidyr. 

Until next time, <br  />
\- Fisher

