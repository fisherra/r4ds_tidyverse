---
title: "R4DS - Reading Data with readr"
author: "Fisher Ankney"
date: "February 13, 2018"
output: html_document
---
This is the second of a six part series summarsing the core concepts of Hadley Wickham's R for Data Science: <http://r4ds.had.co.nz/>. In the previous post, I've written about the R4DS chapters covering data visualization using ggplot2, you can find that post [here](site.baseurl/).

in this post, I'll summarize importing and exporting data with the readr library. While importing data may sound trivial, it can become a hassle when you're faced with parsing date-times, unusual file-types, non-typical encodings, or foreign language syntax. 

For more useful resources on importing data, check out these links:

-
-
-
-


<br  />

#### Load Libraries
```{r, message=FALSE}
library('tidyverse') # used for many amazing things, includes readr library
library('readr')     # used to read in a variety of file types
library('readxl')    # used for reading in microsoft excel files
```

You may also be interested in the following libraries, however I won't cover them in this blog post - 

```{r, eval=FALSE}
library('haven')       # used for SPSS, SAS, and Strata input files
library('DBl')         # used for database files, must combine with specific backend
library('RMySQL')      # used for MySQL backend (with DBl)
library('RSQLite')     # used for SQLLite backend (with DBl)
library('RPostgreSQL') # used for PostgreSQL (with DBl)
```

<br  />

### Reading Data

The readr and readxl libraries gives us a variety of functions that turn flat files into data frames. These are the functions that I find most useful. 

```{r, eval=FALSE}
read_file()     # catch all, useful for .txt files
read_csv()      # comma seperative files
read_tsv()      # tab seperated files
read_xls()      # excel files (from readxl)
```

These readr functions can be used on a variety of paths, some you might not have otherwise known about. 

```{r, eval=FALSE}
# example paths 
read_csv("mtcars.csv")
read_csv("mtcars.csv.zip")
read_csv("~/local/path/to/my/file/mtcars.csv")
read_csv("https://github.com/tidyverse/readr/raw/master/inst/extdata/mtcars.csv")
read_csv("a,b,c
         1,2,3
         4,5,6")
```

In the first example, readr is simply reading in a .csv file found in the current working directory. You can find your current working directory using the base R *getwd( )* function. This is the most basic example of readr's capabiities. 

In the second example line of code, readr is reading in a file that has a .zip extension. readr can unpack compressed files with .zip, .bz2 extensions and similiar.

The third line of code is an example of readr following a local path to a folder in which R isn't currently working in. The initial tilde tells R to start at your predescribed home directory and then follow the file path, sometimes the tilde isn't necssiary if you've already set your R working directory using the *setwd( )* function.

The fourth example is readr following an online path to a described dataset. Go ahead and follow the path and have a look at where it's pointing. 

https://github.com/tidyverse/readr/raw/master/inst/extdata/mtcars.csv

Finally, the last line in the example code above shows how you can create an in-line csv file and read it in directly. This can be useful for creating reproducable examples, such as when you need a question answered on Stack Overflow. 


All of these readr functions can be expanded to include arguements that make your imported data more suitable to analysis. These are the arguements I use the most with readr, but there are many more. Check out ?read_csv in the R terminal for a full description of possible arguements. 

```{r, eval=FALSE}
read_csv("file_name.csv",            # file path and name always comes first
         delim=",",                  # single character field seperator
         quote = "\"",               # single character to quote strings
         comment = "#",              # single character to signal comments
         col_names = c("add", "names", "or", "T/F"), # custom name columns on import
         na = ".",                   # string to signify missing values
         skip = 0,                   # number of lines to skip before reading data
         progress = show_progress()  # display a progress bar
         )
```

<br  />

### Parsing Data

Rarely do you read in files that have clean, correctly structured values. The readr library has a family of parsing functions built to analyze a character string into logical syntactic components. In other words, the parsing family of functions will clean up your data's typing and transform the values into their correct data type. That's the idea anyway. 

Most often I'll use parsing to clean up numbers in a dataset, numeric entries can be surrounded by unwanted characters, such as $100 or 60%. There's also the issue of grouping characters, i.e. 1,000,000 is written instead of 10000000. Finally, you may be working with foreign data that uses the comma as a decimal point instead of the period. Let's go through how to correct these common issues using parsing. 

<br  /> 

##### Numbers - Unwanted Characters
```{r}
a <- "The price is $1993"
str(a)

a <- parse_number(a)
str(a)
```

<br  />



##### Numbers - Decimal Point Problems
```{r}
a <- "1,99"
str(a)

a <- parse_double(a, locale = locale(decimal_mark = ","))
str(a)
```

<br  />


##### Numbers - Grouping Markers
```{r}
a <- "$100.000.000"
str(a)

a <- parse_number(a, locale = locale(grouping_mark = "."))
str(a)
```

<br  />

Dates and times can be confusing since there are so many ways to write them. ISO8601 is an international date-time standard in which the components are ordered largest to smallest - year, month, day and optionally a T followed by hour, minute, second. If no time is specified, the parsing function sets the time to midnight. 

<br  />

#### Date - Times
```{r}
a <- "20180228"
parse_datetime(a)

b <- "2018-02-28T20:10:59"
parse_datetime(b)
```

<br  />

Parsing only dates or only times is also straight forward. The dates function expects a four digit year and a - or / followed by the month with a - or / and the day. The times function expects the hour followed by a colon, :, followed by the minute and another colon, then the second. 

<br  />

#### Dates or Times
```{r}
a <- "2018/02/28"
parse_date(a)

b <- "11:11:11"
parse_time(b)
```

<br  /> 

Say you've got a date-time to parse that isn't in the ISO8601 format, perhaps the months are spelled out, or the data isn't in 24 hour format. Here in the US we often write a date as month-day-year; *parse_datetime( )* won't like that one bit. For these common situations, you can create your own date-time format using these building blocks.

<br  />

##### Year <br  />
%Y - 4 digit year number <br  />
%y - last 2 digit year number; 00-69 = 2000 - 2069, 70-99 = 1970 - 1999 <br  />

##### Month <br  />
%m - 2 digit month number <br  />
%b - abbreviated month name, e.g. "Jan" <br  />
%B - full month name, e.g. "January" <br  />

##### Day <br  />
%d - 2 digit day number <br  />
%e - option leading space <br  />

##### Time  <br  />
%H - 0 to 23 hour <br  />
%I - 0 to 12 hour, must be used with %p <br  />
%p - AM / PM indicator <br  />
%M - minutes  <br  />
%S - integer seconds <br  />
%OS - real seconds <br  />
%Z - time zone, e.g. America/Chicago <br  />
%z - time zone, offset from UTC, e.g. +0800 <br  />

##### Other <br  />
%. - skips one non-digit character <br  />
%* - skips any number of non-digits <br  />

<br  />

#### Custom Date-Times
```{r}
a <- "Jan 7 2018"
parse_date(a, "%b %d %Y")

b <- "12:45 am"
parse_time(b, "%I:%M %p")
```

<br  />





### Writing Data 

#### write_csv()

#### write_excel_csv()

#### ggsave()

